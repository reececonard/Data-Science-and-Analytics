{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Unbiased Evaluation using a New Test Set\n",
    "\n",
    "In this part, we are given a new test set (`/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`). We can now take advantage of the entire smart sample that we created in Part I. \n",
    "\n",
    "* Retrain a pipeline using the optimal parameters that the pipeline learned. We don't need to repeat GridSearch here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load smart sample and the best pipeline from Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_resampled = joblib.load('X_resampled.pkl')\n",
    "\n",
    "y_resampled = joblib.load('y_resampled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "y_pred3 = pickle.load( open( 'my_final_project_model.pkl', \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Retrain a pipeline using the full sampled training data set\n",
    "\n",
    "Use the full sampled training data set to train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E301)\n",
    "# ----------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=30, \n",
    "                                        random_state=42,\n",
    "                                        class_weight=\"balanced\") \n",
    "\n",
    "rfecv = RFECV(estimator=rfc, \n",
    "              step=1, \n",
    "              cv=5, \n",
    "              scoring = 'roc_auc')\n",
    "\n",
    "pipeline  = Pipeline([('feature_sele',rfecv),\n",
    "                      ('rfc',rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GridSearchCV(clf, \n",
    "                      param_grid={'max_depth':[2,3]},\n",
    "                      cv= 5, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_estimators=10,\n",
       "                                              random_state=42),\n",
       "             param_grid={'max_depth': [2, 3]}, scoring='roc_auc')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84      2765\n",
      "           1       0.85      0.80      0.82      2720\n",
      "\n",
      "    accuracy                           0.83      5485\n",
      "   macro avg       0.83      0.83      0.83      5485\n",
      "weighted avg       0.83      0.83      0.83      5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, full_pred, zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model with the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  \n",
    "# -----------------------------\n",
    "\n",
    "filename = 'my_final_project_full_trained_model.pkl'\n",
    "\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(clf1,outfile)\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the Testing Data and evaluate your model\n",
    "\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`\n",
    " \n",
    "* We need to preprocess this test data (follow the steps similar to Part I)\n",
    "* If we have fitted any normalizer/standardizer in Part 2, then we have to transform this test data using the fitted normalizer/standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>3515671</td>\n",
       "      <td>3404784</td>\n",
       "      <td>3391030</td>\n",
       "      <td>3459196</td>\n",
       "      <td>3286519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>150.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_3_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_9_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_1_month</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_3_month</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_9_month</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potential_issue</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_risk</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oe_constraint</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppap_risk</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_stop</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went_on_backorder</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0        1        2        3        4\n",
       "sku                3515671  3404784  3391030  3459196  3286519\n",
       "national_inv         150.0      6.0      6.0      3.0      9.0\n",
       "lead_time              9.0      4.0      8.0      8.0      2.0\n",
       "in_transit_qty         0.0      0.0      0.0      0.0      0.0\n",
       "forecast_3_month       0.0      0.0      2.0      0.0      0.0\n",
       "forecast_6_month       0.0      0.0      5.0      0.0      0.0\n",
       "forecast_9_month       0.0      0.0      8.0      0.0      0.0\n",
       "sales_1_month          1.0      0.0      2.0      0.0      0.0\n",
       "sales_3_month          4.0      0.0      5.0      0.0      0.0\n",
       "sales_6_month         14.0      0.0      9.0      0.0      0.0\n",
       "sales_9_month         25.0      0.0     10.0      0.0      0.0\n",
       "min_bank               2.0      0.0      5.0      0.0      0.0\n",
       "potential_issue         No       No       No       No       No\n",
       "pieces_past_due        0.0      0.0      0.0      0.0      0.0\n",
       "perf_6_month_avg     -99.0     0.73     0.92     0.99      0.8\n",
       "perf_12_month_avg    -99.0     0.78     0.91     0.98     0.83\n",
       "local_bo_qty           0.0      0.0      0.0      0.0      0.0\n",
       "deck_risk               No       No       No       No      Yes\n",
       "oe_constraint           No       No       No       No       No\n",
       "ppap_risk              Yes       No       No       No       No\n",
       "stop_auto_buy          Yes      Yes      Yes      Yes      Yes\n",
       "rev_stop                No       No       No       No       No\n",
       "went_on_backorder       No       No       No       No       No"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the given test set  (Question #E302)\n",
    "# ----------------------------------\n",
    "\n",
    "DATASET = '/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "dataset_2 = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "dataset_2.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_2.drop(columns=['sku', 'min_bank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n"
     ]
    }
   ],
   "source": [
    "yes_no_columns = list(filter(lambda i: dataset_2[i].dtype!=np.float64, dataset_2.columns))\n",
    "print(yes_no_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_issue ['No' 'Yes']\n",
      "deck_risk ['No' 'Yes']\n",
      "oe_constraint ['No' 'Yes']\n",
      "ppap_risk ['Yes' 'No']\n",
      "stop_auto_buy ['Yes' 'No']\n",
      "rev_stop ['No' 'Yes']\n",
      "went_on_backorder ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print('potential_issue', dataset_2['potential_issue'].unique())\n",
    "print('deck_risk', dataset_2['deck_risk'].unique())\n",
    "print('oe_constraint', dataset_2['oe_constraint'].unique())\n",
    "print('ppap_risk', dataset_2['ppap_risk'].unique())\n",
    "print('stop_auto_buy', dataset_2['stop_auto_buy'].unique())\n",
    "print('rev_stop', dataset_2['rev_stop'].unique())\n",
    "print('went_on_backorder', dataset_2['went_on_backorder'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of potential_issue with No\n",
      "Filling missing values of deck_risk with No\n",
      "Filling missing values of oe_constraint with No\n",
      "Filling missing values of ppap_risk with No\n",
      "Filling missing values of stop_auto_buy with Yes\n",
      "Filling missing values of rev_stop with No\n",
      "Filling missing values of went_on_backorder with No\n"
     ]
    }
   ],
   "source": [
    "for column_name in yes_no_columns:\n",
    "    mode = dataset_2[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    dataset_2[column_name].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2['potential_issue'] = dataset_2['potential_issue'].apply(['Yes', 'No'].index)\n",
    "dataset_2['deck_risk'] = dataset_2['deck_risk'].apply(['Yes', 'No'].index)\n",
    "dataset_2['oe_constraint'] = dataset_2['oe_constraint'].apply(['Yes', 'No'].index)\n",
    "dataset_2['ppap_risk'] = dataset_2['ppap_risk'].apply(['Yes', 'No'].index)\n",
    "dataset_2['stop_auto_buy'] = dataset_2['stop_auto_buy'].apply(['Yes', 'No'].index)\n",
    "dataset_2['rev_stop'] = dataset_2['rev_stop'].apply(['Yes', 'No'].index)\n",
    "dataset_2['went_on_backorder'] = dataset_2['went_on_backorder'].apply(['Yes', 'No'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 227351 entries, 0 to 242074\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   national_inv       227351 non-null  float64\n",
      " 1   lead_time          227351 non-null  float64\n",
      " 2   in_transit_qty     227351 non-null  float64\n",
      " 3   forecast_3_month   227351 non-null  float64\n",
      " 4   forecast_6_month   227351 non-null  float64\n",
      " 5   forecast_9_month   227351 non-null  float64\n",
      " 6   sales_1_month      227351 non-null  float64\n",
      " 7   sales_3_month      227351 non-null  float64\n",
      " 8   sales_6_month      227351 non-null  float64\n",
      " 9   sales_9_month      227351 non-null  float64\n",
      " 10  potential_issue    227351 non-null  int64  \n",
      " 11  pieces_past_due    227351 non-null  float64\n",
      " 12  perf_6_month_avg   227351 non-null  float64\n",
      " 13  perf_12_month_avg  227351 non-null  float64\n",
      " 14  local_bo_qty       227351 non-null  float64\n",
      " 15  deck_risk          227351 non-null  int64  \n",
      " 16  oe_constraint      227351 non-null  int64  \n",
      " 17  ppap_risk          227351 non-null  int64  \n",
      " 18  stop_auto_buy      227351 non-null  int64  \n",
      " 19  rev_stop           227351 non-null  int64  \n",
      " 20  went_on_backorder  227351 non-null  int64  \n",
      "dtypes: float64(14), int64(7)\n",
      "memory usage: 38.2 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backorder ratio: 224747 / 227351 = 0.9885463446389063\n"
     ]
    }
   ],
   "source": [
    "num_backorder = np.sum(dataset_2['went_on_backorder']==1)\n",
    "print('backorder ratio:', num_backorder, '/', len(dataset_2), '=', num_backorder / len(dataset_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = dataset_2.went_on_backorder\n",
    "X2 = dataset_2.drop('went_on_backorder', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2604), (1, 2604)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X2_resampled, y2_resampled = rus.fit_resample(X2, y2)\n",
    "print(sorted(Counter(y2_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X2_resampled = scaler.fit_transform(X2_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler() \n",
    "X2_resampled = scaler2.fit_transform(X2_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.11732654e-02 1.39485850e-01 4.05999139e-04 9.42117848e-04\n",
      " 9.28844514e-04 8.85173819e-04 8.81836268e-04 8.63205456e-04\n",
      " 8.24982976e-04 8.05569337e-04 9.99423963e-01 7.25824231e-04\n",
      " 9.82009274e-01 9.86389766e-01 4.96945797e-04 8.48886329e-01\n",
      " 9.99615975e-01 8.77688172e-01 2.82258065e-02 9.99231951e-01]\n",
      "[0.02142387 0.11428358 0.01413135 0.0172961  0.01748448 0.01679379\n",
      " 0.01652108 0.01658029 0.01646857 0.01647986 0.02399385 0.01617544\n",
      " 0.12345868 0.10470889 0.01553004 0.35815964 0.01959278 0.32764561\n",
      " 0.16561736 0.02770305]\n"
     ]
    }
   ],
   "source": [
    "print(X2_resampled.mean(axis=0))\n",
    "print(X2_resampled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y shape: (5208, 20) (5208,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X, y shape:\", X2_resampled.shape, y2_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict and evaluate with the preprocessed test set. It would be interesting to see the performance with and without outliers removal from the test set. We can report confusion matrix, precision, recall, f1-score, accuracy, and other measures (if any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_resampled, y2_resampled, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 1182\n"
     ]
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E303)\n",
    "# ----------------------------------\n",
    "\n",
    "# Performace without outliers\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=2).fit(X2_train, y2_train)\n",
    "\n",
    "lof_outliers = lof.fit_predict(X2_train)==-1\n",
    "print(f\"Num of outliers = {np.sum(lof_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lof = X2_train[~lof_outliers]\n",
    "y_lof = y2_train[~lof_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y shape: (2724, 20) (2724,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X, y shape:\", X_lof.shape, y_lof.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train_lof, X3_test_lof, y3_train_lof, y3_test_lof = train_test_split(X_lof, y_lof, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2179, 20), (545, 20), (2179,), (545,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train_lof.shape, X3_test_lof.shape, y3_train_lof.shape, y3_test_lof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=30, \n",
    "                                        random_state=42,\n",
    "                                        class_weight=\"balanced\") \n",
    "\n",
    "rfecv = RFECV(estimator=rfc, \n",
    "              step=1, \n",
    "              cv=5, \n",
    "              scoring = 'roc_auc')\n",
    "\n",
    "pipeline  = Pipeline([('feature_sele',rfecv),\n",
    "                      ('rfc',rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") \n",
    "\n",
    "clf2 = GridSearchCV(clf, \n",
    "                      param_grid={'max_depth':[2,3]},\n",
    "                      cv= 5, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_estimators=10,\n",
       "                                              random_state=42),\n",
       "             param_grid={'max_depth': [2, 3]}, scoring='roc_auc')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X3_train_lof, y3_train_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       673\n",
      "           1       0.83      0.79      0.81       629\n",
      "\n",
      "    accuracy                           0.82      1302\n",
      "   macro avg       0.82      0.82      0.82      1302\n",
      "weighted avg       0.82      0.82      0.82      1302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = clf2.predict(X2_test)\n",
    "print(classification_report(y2_test, pred1, zero_division = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  569  104\n",
       "1  134  495"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y2_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performace with outliers\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=30, \n",
    "                                        random_state=42,\n",
    "                                        class_weight=\"balanced\") \n",
    "\n",
    "rfecv = RFECV(estimator=rfc, \n",
    "              step=1, \n",
    "              cv=5, \n",
    "              scoring = 'roc_auc')\n",
    "\n",
    "pipeline  = Pipeline([('feature_sele',rfecv),\n",
    "                      ('rfc',rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, \n",
    "                             random_state=42,\n",
    "                             class_weight=\"balanced\") \n",
    "\n",
    "clf3 = GridSearchCV(clf, \n",
    "                      param_grid={'max_depth':[2,3]},\n",
    "                      cv= 5, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_estimators=10,\n",
       "                                              random_state=42),\n",
       "             param_grid={'max_depth': [2, 3]}, scoring='roc_auc')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train) # EDITED for mistake on using outliers before.. correct accuracy score now with outliers included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       673\n",
      "           1       0.48      1.00      0.65       629\n",
      "\n",
      "    accuracy                           0.48      1302\n",
      "   macro avg       0.74      0.50      0.33      1302\n",
      "weighted avg       0.75      0.48      0.31      1302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2 = clf3.predict(X2_test)\n",
    "print(classification_report(y2_test, pred2, zero_division = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  673\n",
       "1  0  629"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y2_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a summary of your processing and an analysis of the model performance  \n",
    "# (Question #E304)\n",
    "# ----------------------------------\n",
    "\n",
    "Model performance was better on the Test Data without outliers at 82% up from 48% when outliers were left in the model, which would be expected because they can skew the results. However, the full sampled training set had the highest accuracy rating 83%. Overall it performed almost as well on the testing dataset as it did on both the sampled and full sampled training dataset. Which I believe inidcates that it is a good model and generalizes well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect\n",
    "\n",
    "Imagine you are data scientist that has been tasked with developing a system to save your \n",
    "company money by predicting and preventing back orders of parts in the supply cha\n",
    "Write a **brief summary** for \"management\" that details your findings, \n",
    "your level of certainty and trust in the models, \n",
    "and recommendations for operationalizing these models for the business."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your answer here:  \n",
    "# (Question #E305)\n",
    "# ----------------------------------\n",
    "\n",
    "Given the different metrics of the data, we are able to predict how much inventory we should have at a given time. This will directly correclate to the companys bottom dollar in saving money with preventing back orders that cause the company to lose business. I have a high amount of certainty in the accuracy in the model, and can difinitively say that it will improve the businesses operations in a net fashion. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
